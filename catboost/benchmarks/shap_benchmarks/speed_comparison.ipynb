{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speed comparison of gradient boosting libraries for shap values calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we compare CatBoost, LightGBM and XGBoost for shap values calculations. All boosting algorithms trained on GPU but shap evaluation was on CPU.\n",
    "\n",
    "We use epsilon_normalized dataset from [here](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import copy\n",
    "import tqdm\n",
    "import datetime\n",
    "from sklearn import datasets\n",
    "import catboost\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0.11.2', '2.2.2', '0.81')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catboost.__version__, lgb.__version__, xgb.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_target = datasets.load_svmlight_file(\"epsilon_normalized\")\n",
    "test_data, test_target = datasets.load_svmlight_file(\"epsilon_normalized.t\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iters = 1000\n",
    "lr = 0.1\n",
    "max_bin = 128\n",
    "gpu_device = '0' # specify your GPU (used only for training)\n",
    "random_state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target[train_target == -1] = 0\n",
    "test_target[test_target == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, label=None, mode='train', boosting=None):\n",
    "    assert boosting is not None\n",
    "    \n",
    "    if isinstance(data, scipy.sparse.csr_matrix):\n",
    "        data = data.todense().A\n",
    "    \n",
    "    if boosting == 'xgboost':\n",
    "        return xgb.DMatrix(data, label)\n",
    "    elif boosting == 'lightgbm':\n",
    "        if mode == 'train':\n",
    "            return lgb.Dataset(data, label)\n",
    "        else:\n",
    "            return data\n",
    "    elif boosting == 'catboost':\n",
    "        return catboost.Pool(data, label)\n",
    "    else:\n",
    "        raise RuntimeError(\"Unknown boosting library\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parameters(base_params, boosting=None, **kwargs):\n",
    "    assert boosting is not None\n",
    "    assert isinstance(base_params, dict)\n",
    "    \n",
    "    params = copy.copy(base_params)\n",
    "    if boosting == 'xgboost':\n",
    "        params['objective'] = 'binary:logistic'\n",
    "        params['max_depth'] = kwargs['depth']\n",
    "        params['tree_method'] = 'gpu_hist'\n",
    "        params['gpu_id'] = gpu_device\n",
    "    elif boosting == 'lightgbm':\n",
    "        params['objective'] = 'binary'\n",
    "        params['device'] = \"gpu\"\n",
    "        params['gpu_device_id'] = gpu_device\n",
    "        params['num_leaves'] = 2**kwargs['depth']\n",
    "    elif boosting == 'catboost':\n",
    "        params['objective'] = 'Logloss'\n",
    "        params['task_type'] = 'GPU'\n",
    "        params['devices'] = gpu_device\n",
    "        params['bootstrap_type'] = 'Bernoulli'\n",
    "        params['logging_level'] = 'Silent'\n",
    "    else:\n",
    "        raise RuntimeError(\"Unknown boosting library\")\n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, params, num_iters, boosting=None):\n",
    "    assert boosting is not None\n",
    "    if boosting == 'xgboost':\n",
    "        return xgb.train(params=params, dtrain=data, num_boost_round=num_iters)\n",
    "    elif boosting == 'lightgbm':\n",
    "        return lgb.train(params=params, train_set=data, num_boost_round=num_iters)\n",
    "    elif boosting == 'catboost':\n",
    "        return catboost.train(pool=data, params=params, num_boost_round=num_iters)\n",
    "    else:\n",
    "        raise RuntimeError(\"Unknown boosting library\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_shap(model, data, boosting=None):\n",
    "    assert boosting is not None\n",
    "    if boosting == 'xgboost':\n",
    "        return model.predict(data, pred_contribs=True)\n",
    "    elif boosting == 'lightgbm':\n",
    "        return model.predict(data, pred_contrib=True)\n",
    "    elif boosting == 'catboost':\n",
    "        return model.get_feature_importance(data, fstr_type='ShapValues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_path(boosting, params):\n",
    "    fname = [boosting]\n",
    "    for key, value in sorted(params.items()):\n",
    "        fname.append(str(key))\n",
    "        fname.append(str(value))\n",
    "    fname = \"_\".join(fname)\n",
    "    fname = fname.replace(\".\", '')\n",
    "    fname += \".model\"\n",
    "    return fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(fname, boosting):\n",
    "    if boosting == \"xgboost\":\n",
    "        bst = xgb.Booster(model_file=fname)\n",
    "        bst.load_model(fname)\n",
    "    elif boosting == \"lightgbm\":\n",
    "        bst = lgb.Booster(model_file=fname)\n",
    "    elif boosting == \"catboost\":\n",
    "        bst = catboost.CatBoost()\n",
    "        bst.load_model(fname)\n",
    "    else:\n",
    "        raise RuntimeError(\"Unknown boosting\")\n",
    "    return bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_params = {\n",
    "    'learning_rate': lr,\n",
    "    'max_bin': max_bin,\n",
    "    'random_state': random_state\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "boosting_list = ['xgboost', 'catboost', 'lightgbm']\n",
    "depth_list = [2, 4, 6, 8, 10]\n",
    "lens_list = [1000, 5000, 10000]\n",
    "\n",
    "\n",
    "for gb_type in boosting_list:\n",
    "    \n",
    "    print(\"{} is going\".format(gb_type))\n",
    "    \n",
    "    for size_test in lens_list:\n",
    "        print(\"size test {}\".format(size_test))\n",
    "        sep_test_data = test_data[:size_test]\n",
    "        sep_test_target = test_target[:size_test]\n",
    "        \n",
    "        # comment this line if you have already trained all models\n",
    "#         train_preprocessed = preprocess_data(train_data, train_target, boosting=gb_type)\n",
    "        \n",
    "        start_test_preproc = datetime.datetime.now()\n",
    "        test_preprocessed = preprocess_data(sep_test_data,\n",
    "                                            sep_test_target, \n",
    "                                            mode='test',\n",
    "                                            boosting=gb_type)\n",
    "        \n",
    "        finish_test_preproc = datetime.datetime.now()\n",
    "        preprocessing_delta = finish_test_preproc - start_test_preproc\n",
    "        preprocessing_delta = preprocessing_delta.total_seconds()\n",
    "\n",
    "        for depth in tqdm.tqdm(depth_list):\n",
    "\n",
    "            params = create_parameters(base_params, boosting=gb_type, depth=depth)\n",
    "            params['depth'] = depth\n",
    "            fname = create_path(gb_type, params)\n",
    "            if os.path.exists(fname):\n",
    "                print(\"model exist\")\n",
    "                bst = load_model(fname, boosting=gb_type)\n",
    "            else:\n",
    "                print(\"model is training\")\n",
    "                start_train = datetime.datetime.now()\n",
    "                bst = train(train_preprocessed, params, num_iters=num_iters, boosting=gb_type)\n",
    "                finish_train = datetime.datetime.now()\n",
    "                delta_train = finish_train - start_train\n",
    "                delta_train = int(delta_train.total_seconds() * 1000)\n",
    "                bst.save_model(fname)\n",
    "\n",
    "            start_time = datetime.datetime.now()\n",
    "            preds = predict_shap(bst, test_preprocessed, boosting=gb_type)\n",
    "            assert preds.shape == (sep_test_data.shape[0], sep_test_data.shape[1] + 1)\n",
    "            finish_time = datetime.datetime.now()\n",
    "\n",
    "            delta = finish_time - start_time\n",
    "            delta = delta.total_seconds()\n",
    "\n",
    "            current_res = {\n",
    "            'preprocessing_time': preprocessing_delta,\n",
    "            'boosting': gb_type,\n",
    "            'test_size': size_test,\n",
    "            'depth': depth,\n",
    "            'time': delta,\n",
    "            }\n",
    "\n",
    "            result.append(current_res)\n",
    "\n",
    "        print(\"*\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>boosting</th>\n",
       "      <th>depth</th>\n",
       "      <th>preprocessing_time</th>\n",
       "      <th>test_size</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032169</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.122303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>4</td>\n",
       "      <td>0.032169</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.359745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  boosting  depth  preprocessing_time  test_size      time\n",
       "0  xgboost      2            0.032169       1000  0.122303\n",
       "1  xgboost      4            0.032169       1000  0.359745"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(result)\n",
    "result_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"shap_benchmark_{}_max_bin_with_test_sizes.csv\".format(max_bin), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>boosting</th>\n",
       "      <th>catboost</th>\n",
       "      <th>lightgbm</th>\n",
       "      <th>xgboost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_size</th>\n",
       "      <th>depth</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1000</th>\n",
       "      <th>2</th>\n",
       "      <td>0.347305</td>\n",
       "      <td>0.151798</td>\n",
       "      <td>0.122303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.311610</td>\n",
       "      <td>0.616553</td>\n",
       "      <td>0.359745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.608989</td>\n",
       "      <td>4.603050</td>\n",
       "      <td>1.617491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.366012</td>\n",
       "      <td>25.368088</td>\n",
       "      <td>8.667185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>95.616110</td>\n",
       "      <td>124.203530</td>\n",
       "      <td>33.386224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">5000</th>\n",
       "      <th>2</th>\n",
       "      <td>1.183472</td>\n",
       "      <td>0.336318</td>\n",
       "      <td>0.277421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.083023</td>\n",
       "      <td>2.424311</td>\n",
       "      <td>1.178953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.341792</td>\n",
       "      <td>22.168660</td>\n",
       "      <td>7.372275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.089256</td>\n",
       "      <td>123.646465</td>\n",
       "      <td>41.763362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>96.289186</td>\n",
       "      <td>602.586856</td>\n",
       "      <td>161.828450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">10000</th>\n",
       "      <th>2</th>\n",
       "      <td>2.205630</td>\n",
       "      <td>0.575600</td>\n",
       "      <td>0.619787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.251814</td>\n",
       "      <td>4.446244</td>\n",
       "      <td>2.239409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.422703</td>\n",
       "      <td>43.581631</td>\n",
       "      <td>14.320611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.035649</td>\n",
       "      <td>247.878384</td>\n",
       "      <td>83.086572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>99.835549</td>\n",
       "      <td>1237.044082</td>\n",
       "      <td>323.153527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "boosting          catboost     lightgbm     xgboost\n",
       "test_size depth                                    \n",
       "1000      2       0.347305     0.151798    0.122303\n",
       "          4       0.311610     0.616553    0.359745\n",
       "          6       0.608989     4.603050    1.617491\n",
       "          8       5.366012    25.368088    8.667185\n",
       "          10     95.616110   124.203530   33.386224\n",
       "5000      2       1.183472     0.336318    0.277421\n",
       "          4       1.083023     2.424311    1.178953\n",
       "          6       1.341792    22.168660    7.372275\n",
       "          8       6.089256   123.646465   41.763362\n",
       "          10     96.289186   602.586856  161.828450\n",
       "10000     2       2.205630     0.575600    0.619787\n",
       "          4       2.251814     4.446244    2.239409\n",
       "          6       2.422703    43.581631   14.320611\n",
       "          8       7.035649   247.878384   83.086572\n",
       "          10     99.835549  1237.044082  323.153527"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.read_csv(\"shap_benchmark_128_max_bin_with_test_sizes.csv\", )\n",
    "result_df.pivot_table(index=[\"test_size\", \"depth\"], columns=\"boosting\", values=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>boosting</th>\n",
       "      <th>catboost</th>\n",
       "      <th>lightgbm</th>\n",
       "      <th>xgboost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.798758</td>\n",
       "      <td>0.016927</td>\n",
       "      <td>0.032169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>1.424891</td>\n",
       "      <td>0.032507</td>\n",
       "      <td>0.124385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>3.091871</td>\n",
       "      <td>0.050151</td>\n",
       "      <td>0.271677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "boosting   catboost  lightgbm   xgboost\n",
       "test_size                              \n",
       "1000       0.798758  0.016927  0.032169\n",
       "5000       1.424891  0.032507  0.124385\n",
       "10000      3.091871  0.050151  0.271677"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.pivot_table(index=\"test_size\", columns=\"boosting\", values=\"preprocessing_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
