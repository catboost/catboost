{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speed comparison of gradient boosting libraries for shap values calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we compare CatBoost, LightGBM and XGBoost for shap values calculations on GPU.\n",
    "\n",
    "We used Titan X Pascal for training and evaluation.\n",
    "\n",
    "We use epsilon_normalized dataset from [here](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import copy\n",
    "import tqdm\n",
    "import datetime\n",
    "from sklearn import datasets\n",
    "import catboost\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0.11.1', '2.2.3', '0.81')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catboost.__version__, lgb.__version__, xgb.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400000, 2000), (400000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, train_target = datasets.load_svmlight_file(\"epsilon_normalized\",)\n",
    "test_data, test_target = datasets.load_svmlight_file(\"epsilon_normalized.t\",)\n",
    "train_data.shape, train_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iters = 1000\n",
    "lr = 0.1\n",
    "max_bin = 128\n",
    "gpu_device = '1'\n",
    "random_state = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use only 10k samples from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = 10000\n",
    "\n",
    "train_target[train_target == -1] = 0\n",
    "test_target[test_target == -1] = 0\n",
    "\n",
    "test_data = test_data[:sep]\n",
    "test_target = test_target[:sep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, label=None, mode='train', boosting=None):\n",
    "    assert boosting is not None\n",
    "    \n",
    "    if isinstance(data, scipy.sparse.csr_matrix):\n",
    "        data = data.todense().A\n",
    "    \n",
    "    if boosting == 'xgboost':\n",
    "        return xgb.DMatrix(data, label)\n",
    "    elif boosting == 'lightgbm':\n",
    "        if mode == 'train':\n",
    "            return lgb.Dataset(data, label)\n",
    "        else:\n",
    "            return data\n",
    "    elif boosting == 'catboost':\n",
    "        return catboost.Pool(data, label)\n",
    "    else:\n",
    "        raise RuntimeError(\"Unknown boosting library\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parameters(base_params, boosting=None, **kwargs):\n",
    "    assert boosting is not None\n",
    "    assert isinstance(base_params, dict)\n",
    "    \n",
    "    params = copy.copy(base_params)\n",
    "    if boosting == 'xgboost':\n",
    "        params['objective'] = 'binary:logistic'\n",
    "        params['max_depth'] = kwargs['depth']\n",
    "        params['tree_method'] = 'gpu_hist'\n",
    "        params['gpu_id'] = gpu_device\n",
    "    elif boosting == 'lightgbm':\n",
    "        params['objective'] = 'binary'\n",
    "        params['device'] = \"gpu\"\n",
    "        params['gpu_device_id'] = gpu_device\n",
    "        params['num_leaves'] = 2**kwargs['depth']\n",
    "    elif boosting == 'catboost':\n",
    "        params['objective'] = 'Logloss'\n",
    "        params['task_type'] = 'GPU'\n",
    "        params['devices'] = gpu_device\n",
    "        params['bootstrap_type'] = 'Bernoulli'\n",
    "        params['logging_level'] = 'Silent'\n",
    "    else:\n",
    "        raise RuntimeError(\"Unknown boosting library\")\n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, params, num_iters, boosting=None):\n",
    "    assert boosting is not None\n",
    "    if boosting == 'xgboost':\n",
    "        return xgb.train(params=params, dtrain=data, num_boost_round=num_iters)\n",
    "    elif boosting == 'lightgbm':\n",
    "        return lgb.train(params=params, train_set=data, num_boost_round=num_iters)\n",
    "    elif boosting == 'catboost':\n",
    "        return catboost.train(pool=data, params=params, num_boost_round=num_iters)\n",
    "    else:\n",
    "        raise RuntimeError(\"Unknown boosting library\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_shap(model, data, boosting=None):\n",
    "    assert boosting is not None\n",
    "    if boosting == 'xgboost':\n",
    "        return model.predict(data, pred_contribs=True)\n",
    "    elif boosting == 'lightgbm':\n",
    "        return model.predict(data, pred_contrib=True)\n",
    "    elif boosting == 'catboost':\n",
    "        return model.get_feature_importance(data, fstr_type='ShapValues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_path(boosting, params):\n",
    "    fname = [boosting]\n",
    "    for key, value in sorted(params.items()):\n",
    "        fname.append(str(key))\n",
    "        fname.append(str(value))\n",
    "    fname = \"_\".join(fname)\n",
    "    fname = fname.replace(\".\", '')\n",
    "    fname += \".model\"\n",
    "    return fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(fname, boosting):\n",
    "    if boosting == \"xgboost\":\n",
    "        bst = xgb.Booster(model_file=fname)\n",
    "        bst.load_model(fname)\n",
    "    elif boosting == \"lightgbm\":\n",
    "        bst = lgb.Booster(model_file=fname)\n",
    "    elif boosting == \"catboost\":\n",
    "        bst = catboost.CatBoost()\n",
    "        bst.load_model(fname)\n",
    "    else:\n",
    "        raise RuntimeError(\"Unknown boosting\")\n",
    "    return bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_params = {\n",
    "    'learning_rate': lr,\n",
    "    'max_bin': max_bin,\n",
    "    'random_state': random_state\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost is going\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [10:33<42:14, 633.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [25:27<38:10, 763.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [44:29<29:39, 889.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [1:10:28<17:37, 1057.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [2:00:04<00:00, 1440.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n",
      "catboost is going\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [00:02<00:08,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [00:04<00:06,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [00:06<00:04,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [00:13<00:03,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:49<00:00, 21.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n",
      "lightgbm is going\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [00:00<00:02,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [00:04<00:07,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [00:46<00:30, 15.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [04:42<01:10, 70.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 5/5 [24:31<00:00, 294.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "boosting_list = ['xgboost', 'catboost', 'lightgbm']\n",
    "depth_list = [2, 4, 6, 8, 10]\n",
    "\n",
    "\n",
    "for gb_type in boosting_list:\n",
    "    \n",
    "    print(\"{} is going\".format(gb_type))\n",
    "    train_preprocessed = preprocess_data(train_data, train_target, boosting=gb_type)\n",
    "    test_preprocessed = preprocess_data(test_data, test_target, mode='test',boosting=gb_type)\n",
    "    \n",
    "    for depth in tqdm.tqdm(depth_list):\n",
    "        \n",
    "        params = create_parameters(base_params, boosting=gb_type, depth=depth)\n",
    "        params['depth'] = depth\n",
    "        fname = create_path(gb_type, params)\n",
    "        if os.path.exists(fname):\n",
    "            print(\"model exist\")\n",
    "            bst = load_model(fname, boosting=gb_type)\n",
    "        else:\n",
    "            print(\"model is training\")\n",
    "            start_train = datetime.datetime.now()\n",
    "            bst = train(train_preprocessed, params, num_iters=num_iters, boosting=gb_type)\n",
    "            finish_train = datetime.datetime.now()\n",
    "            delta_train = finish_train - start_train\n",
    "            delta_train = int(delta_train.total_seconds() * 1000)\n",
    "            bst.save_model(fname)\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "        preds = predict_shap(bst, test_preprocessed, boosting=gb_type)\n",
    "        assert preds.shape == (test_data.shape[0], test_data.shape[1] + 1)\n",
    "        finish_time = datetime.datetime.now()\n",
    "\n",
    "        delta = finish_time - start_time\n",
    "        delta = int(delta.total_seconds() * 1000)\n",
    "\n",
    "        current_res = {\n",
    "        'boosting': gb_type,\n",
    "        'depth': depth,\n",
    "        'time': delta,\n",
    "        }\n",
    "\n",
    "        result.append(current_res)\n",
    "            \n",
    "    print(\"*\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\* We trained some models before and didn't train them again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>boosting</th>\n",
       "      <th>depth</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>2</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>4</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  boosting  depth  time\n",
       "0  xgboost      2   495\n",
       "1  xgboost      4  1996"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(result)\n",
    "result_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"shap_benchmark_{}_max_bin.csv\".format(max_bin), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depth</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>6</th>\n",
       "      <th>8</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boosting</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>catboost</th>\n",
       "      <td>2.145</td>\n",
       "      <td>2.079</td>\n",
       "      <td>2.515</td>\n",
       "      <td>7.190</td>\n",
       "      <td>95.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lightgbm</th>\n",
       "      <td>0.502</td>\n",
       "      <td>4.241</td>\n",
       "      <td>41.210</td>\n",
       "      <td>236.708</td>\n",
       "      <td>1188.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <td>0.495</td>\n",
       "      <td>1.996</td>\n",
       "      <td>12.864</td>\n",
       "      <td>74.940</td>\n",
       "      <td>298.284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           time                                  \n",
       "depth        2      4       6        8         10\n",
       "boosting                                         \n",
       "catboost  2.145  2.079   2.515    7.190    95.030\n",
       "lightgbm  0.502  4.241  41.210  236.708  1188.494\n",
       "xgboost   0.495  1.996  12.864   74.940   298.284"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.read_csv(\"shap_benchmark_128_max_bin.csv\", )\n",
    "result_df['time'] = result_df['time'] / 1000.\n",
    "result_df.pivot_table(index=\"boosting\", columns=\"depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
