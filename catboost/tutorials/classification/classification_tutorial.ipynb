{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving classification problems with CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will use dataset Amazon Employee Access Challenge from [Kaggle](https://www.kaggle.com) competition for our experiments. Data can be downloaded [here](https://www.kaggle.com/c/amazon-employee-access-challenge/data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --user --upgrade catboost\n",
    "#!pip install --user --upgrade ipywidgets\n",
    "#!pip install shap\n",
    "#!pip install sklearn\n",
    "#!pip install --upgrade numpy\n",
    "#!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost\n",
    "print(catboost.__version__)\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "import catboost\n",
    "from catboost import *\n",
    "from catboost import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_df, test_df) = catboost.datasets.amazon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label values extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df.ACTION\n",
    "X = train_df.drop('ACTION', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical features declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = list(range(0, X.shape[1]))\n",
    "print(cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking on label balance in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Labels: {}'.format(set(y)))\n",
    "print('Zero count = {}, One count = {}'.format(len(y) - sum(y), sum(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ways to create Pool class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = './amazon'\n",
    "if not os.path.exists(dataset_dir):\n",
    "    os.makedirs(dataset_dir)\n",
    "\n",
    "# We will be able to work with files with/without header and\n",
    "# with different separators.\n",
    "train_df.to_csv(\n",
    "    os.path.join(dataset_dir, 'train.tsv'),\n",
    "    index=False, sep='\\t', header=False\n",
    ")\n",
    "test_df.to_csv(\n",
    "    os.path.join(dataset_dir, 'test.tsv'),\n",
    "    index=False, sep='\\t', header=False\n",
    ")\n",
    "\n",
    "train_df.to_csv(\n",
    "    os.path.join(dataset_dir, 'train.csv'),\n",
    "    index=False, sep=',', header=True\n",
    ")\n",
    "test_df.to_csv(\n",
    "    os.path.join(dataset_dir, 'test.csv'),\n",
    "    index=False, sep=',', header=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head amazon/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost.utils import create_cd\n",
    "feature_names = dict()\n",
    "for column, name in enumerate(train_df):\n",
    "    if column == 0:\n",
    "        continue\n",
    "    feature_names[column - 1] = name\n",
    "    \n",
    "create_cd(\n",
    "    label=0, \n",
    "    cat_features=list(range(1, train_df.columns.shape[0])),\n",
    "    feature_names=feature_names,\n",
    "    output_path=os.path.join(dataset_dir, 'train.cd')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat amazon/train.cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool1 = Pool(data=X, label=y, cat_features=cat_features)\n",
    "pool2 = Pool(\n",
    "    data=os.path.join(dataset_dir, 'train.csv'), \n",
    "    delimiter=',', \n",
    "    column_description=os.path.join(dataset_dir, 'train.cd'),\n",
    "    has_header=True\n",
    ")\n",
    "pool3 = Pool(data=X, cat_features=cat_features)\n",
    "\n",
    "# Fastest way to create a Pool is to create it from numpy matrix.\n",
    "# This way should be used if you want fast predictions\n",
    "# or fastest way to load the data in python.\n",
    "\n",
    "X_prepared = X.values.astype(str).astype(object)\n",
    "# For FeaturesData class categorial features must have type str\n",
    "\n",
    "pool4 = Pool(\n",
    "    data=FeaturesData(\n",
    "        cat_feature_data=X_prepared,\n",
    "        cat_feature_names=list(X)\n",
    "    ),\n",
    "    label=y.values\n",
    ")\n",
    "\n",
    "print('Dataset shape')\n",
    "print('dataset 1:' + str(pool1.shape) +\n",
    "      '\\ndataset 2:' + str(pool2.shape) + \n",
    "      '\\ndataset 3:' + str(pool3.shape) +\n",
    "      '\\ndataset 4: ' + str(pool4.shape))\n",
    "\n",
    "print('\\n')\n",
    "print('Column names')\n",
    "print('dataset 1:')\n",
    "print(pool1.get_feature_names()) \n",
    "print('\\ndataset 2:')\n",
    "print(pool2.get_feature_names())\n",
    "print('\\ndataset 3:')\n",
    "print(pool3.get_feature_names())\n",
    "print('\\ndataset 4:')\n",
    "print(pool4.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split your data into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, train_size=0.8, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible options for binary classification:\n",
    "\n",
    "`Logloss`\n",
    "\n",
    "`CrossEntropy` for probabilities in target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=5,\n",
    "    learning_rate=0.1,\n",
    "    # loss_function='CrossEntropy'\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    verbose=False\n",
    ")\n",
    "print('Model is fitted: ' + str(model.is_fitted()))\n",
    "print('Model params:')\n",
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stdout of the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=15,\n",
    "#     verbose=5,\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics calculation and graph plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=50,\n",
    "    random_seed=63,\n",
    "    learning_rate=0.5,\n",
    "    custom_loss=['AUC', 'Accuracy']\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    verbose=False,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = CatBoostClassifier(\n",
    "    learning_rate=0.7,\n",
    "    iterations=100,\n",
    "    random_seed=0,\n",
    "    train_dir='learing_rate_0.7'\n",
    ")\n",
    "\n",
    "model2 = CatBoostClassifier(\n",
    "    learning_rate=0.01,\n",
    "    iterations=100,\n",
    "    random_seed=0,\n",
    "    train_dir='learing_rate_0.01'\n",
    ")\n",
    "model1.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    cat_features=cat_features,\n",
    "    verbose=False\n",
    ")\n",
    "model2.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    cat_features=cat_features,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import MetricVisualizer\n",
    "MetricVisualizer(['learing_rate_0.01', 'learing_rate_0.7']).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=100,\n",
    "    random_seed=63,\n",
    "    learning_rate=0.5,\n",
    "#     use_best_model=False\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    verbose=False,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tree count: ' + str(model.tree_count_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import cv\n",
    "\n",
    "params = {}\n",
    "params['loss_function'] = 'Logloss'\n",
    "params['iterations'] = 80\n",
    "params['custom_loss'] = 'AUC'\n",
    "params['random_seed'] = 63\n",
    "params['learning_rate'] = 0.5\n",
    "\n",
    "cv_data = cv(\n",
    "    params = params,\n",
    "    pool = Pool(X, label=y, cat_features=cat_features),\n",
    "    fold_count=5,\n",
    "    shuffle=True,\n",
    "    partition_random_seed=0,\n",
    "    plot=True,\n",
    "    stratified=False,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_value = np.min(cv_data['test-Logloss-mean'])\n",
    "best_iter = np.argmin(cv_data['test-Logloss-mean'])\n",
    "\n",
    "print('Best validation Logloss score, not stratified: {:.4f}±{:.4f} on step {}'.format(\n",
    "    best_value,\n",
    "    cv_data['test-Logloss-std'][best_iter],\n",
    "    best_iter)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_data = cv(\n",
    "    params = params,\n",
    "    pool = Pool(X, label=y, cat_features=cat_features),\n",
    "    fold_count=5,\n",
    "    inverted=False,\n",
    "    shuffle=True,\n",
    "    partition_random_seed=0,\n",
    "    plot=True,\n",
    "    stratified=True,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "best_value = np.min(cv_data['test-Logloss-mean'])\n",
    "best_iter = np.argmin(cv_data['test-Logloss-mean'])\n",
    "\n",
    "print('Best validation Logloss score, stratified: {:.4f}±{:.4f} on step {}'.format(\n",
    "    best_value,\n",
    "    cv_data['test-Logloss-std'][best_iter],\n",
    "    best_iter)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_early_stop = CatBoostClassifier(\n",
    "    iterations=200,\n",
    "    random_seed=63,\n",
    "    learning_rate=0.5,\n",
    "    early_stopping_rounds=20\n",
    ")\n",
    "model_with_early_stop.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    verbose=False,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_with_early_stop.tree_count_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_early_stop = CatBoostClassifier(\n",
    "    eval_metric='AUC',\n",
    "    iterations=200,\n",
    "    random_seed=63,\n",
    "    learning_rate=0.5,\n",
    "    early_stopping_rounds=20\n",
    ")\n",
    "model_with_early_stop.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    verbose=False,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_with_early_stop.tree_count_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    random_seed=63,\n",
    "    iterations=200,\n",
    "    learning_rate=0.03,\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    verbose=False,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://habrastorage.org/webt/y4/1q/yq/y41qyqfm9mcerp2ziys48phpjia.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost.utils import get_roc_curve\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "\n",
    "eval_pool = Pool(X_validation, y_validation, cat_features=cat_features)\n",
    "curve = get_roc_curve(model, eval_pool)\n",
    "(fpr, tpr, thresholds) = curve\n",
    "roc_auc = sklearn.metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "lw = 2\n",
    "\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc, alpha=0.5)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.xlabel('False Positive Rate', fontsize=16)\n",
    "plt.ylabel('True Positive Rate', fontsize=16)\n",
    "plt.title('Receiver operating characteristic', fontsize=20)\n",
    "plt.legend(loc=\"lower right\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost.utils import get_fpr_curve\n",
    "from catboost.utils import get_fnr_curve\n",
    "\n",
    "(thresholds, fpr) = get_fpr_curve(curve=curve)\n",
    "(thresholds, fnr) = get_fnr_curve(curve=curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "lw = 2\n",
    "\n",
    "plt.plot(thresholds, fpr, color='blue', lw=lw, label='FPR', alpha=0.5)\n",
    "plt.plot(thresholds, fnr, color='green', lw=lw, label='FNR', alpha=0.5)\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Threshold', fontsize=16)\n",
    "plt.ylabel('Error Rate', fontsize=16)\n",
    "plt.title('FPR-FNR curves', fontsize=20)\n",
    "plt.legend(loc=\"lower left\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost.utils import select_threshold\n",
    "\n",
    "print(select_threshold(model=model, data=eval_pool, FNR=0.01))\n",
    "print(select_threshold(model=model, data=eval_pool, FPR=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snapshotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !rm 'catboost_info/snapshot.bkp'\n",
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=100,\n",
    "    save_snapshot=True,\n",
    "    snapshot_file='snapshot.bkp',\n",
    "    snapshot_interval=1,\n",
    "    random_seed=43\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    cat_features=cat_features,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict_proba(data=X_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict(data=X_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_pred = model.predict(\n",
    "    data=X_validation,\n",
    "    prediction_type='RawFormulaVal'\n",
    ")\n",
    "print(raw_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import exp\n",
    "\n",
    "sigmoid = lambda x: 1 / (1 + exp(-x))\n",
    "\n",
    "probabilities = sigmoid(raw_pred)\n",
    "\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prepared = X_validation.values.astype(str).astype(object)\n",
    "# For FeaturesData class categorial features must have type str\n",
    "\n",
    "fast_predictions = model.predict_proba(\n",
    "    data=FeaturesData(\n",
    "        cat_feature_data=X_prepared,\n",
    "        cat_feature_names=list(X_validation)\n",
    "    )\n",
    ")\n",
    "print(fast_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Staged prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_gen = model.staged_predict_proba(\n",
    "    data=X_validation,\n",
    "    ntree_start=0, \n",
    "    ntree_end=5, \n",
    "    eval_period=1\n",
    ")\n",
    "try:\n",
    "    for iteration, predictions in enumerate(predictions_gen):\n",
    "        print('Iteration ' + str(iteration) + ', predictions:')\n",
    "        print(predictions)\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving MultiClassification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=50,\n",
    "    random_seed=43,\n",
    "    loss_function='MultiClass'\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    verbose=False,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For multiclass problems with many classes sometimes it's better to solve classification problem using ranking.\n",
    "To do that we will build a dataset with groups.\n",
    "Every group will represent one object from our initial dataset.\n",
    "But it will have one additional categorical feature - possible class value.\n",
    "Target values will be equal to 1 if the class value is equal to the correct class, and 0 otherwise.\n",
    "Thus each group will have exactly one 1 in labels, and some zeros.\n",
    "You can put all possible class values in the group or you can try setting only hard negatives if there are too many labels.\n",
    "We'll show this approach on an example of binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "def build_multiclass_ranking_dataset(X, y, cat_features, label_values=[0,1], start_group_id=0):\n",
    "    ranking_matrix = []\n",
    "    ranking_labels = []\n",
    "    group_ids = []\n",
    "\n",
    "    X_train_matrix = X.values\n",
    "    y_train_vector = y.values\n",
    "\n",
    "    for obj_idx in range(X.shape[0]):\n",
    "        obj = list(X_train_matrix[obj_idx])\n",
    "\n",
    "        for label in label_values:\n",
    "            obj_of_given_class = deepcopy(obj)\n",
    "            obj_of_given_class.append(label)\n",
    "            ranking_matrix.append(obj_of_given_class)\n",
    "            ranking_labels.append(float(y_train_vector[obj_idx] == label)) \n",
    "            group_ids.append(start_group_id + obj_idx)\n",
    "        \n",
    "    final_cat_features = deepcopy(cat_features)\n",
    "    final_cat_features.append(X.shape[1]) # new feature that we are adding should be categorical.\n",
    "    return Pool(ranking_matrix, ranking_labels, cat_features=final_cat_features, group_id = group_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoost\n",
    "params = {'iterations':150, 'learning_rate':0.01, 'l2_leaf_reg':30, 'random_seed':0, 'loss_function':'QuerySoftMax'}\n",
    "\n",
    "groupwise_train_pool = build_multiclass_ranking_dataset(X_train, y_train, cat_features, [0,1])\n",
    "groupwise_eval_pool = build_multiclass_ranking_dataset(X_validation, y_validation, cat_features, [0,1], X_train.shape[0])\n",
    "\n",
    "model = CatBoost(params)\n",
    "model.fit(\n",
    "    X=groupwise_train_pool,\n",
    "    verbose=False,\n",
    "    eval_set=groupwise_eval_pool,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing predictions with ranking mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "obj = list(X_validation.values[0])\n",
    "ratings = []\n",
    "for label in [0,1]:\n",
    "    obj_with_label = deepcopy(obj)\n",
    "    obj_with_label.append(label)\n",
    "    rating = model.predict([obj_with_label])[0]\n",
    "    ratings.append(rating)\n",
    "print('Raw values:', np.array(ratings))\n",
    "\n",
    "def soft_max(values):\n",
    "    return [math.exp(val) / sum([math.exp(val) for val in values]) for val in values]\n",
    "\n",
    "print('Probabilities', np.array(soft_max(ratings)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric evaluation on a new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    random_seed=63,\n",
    "    iterations=200,\n",
    "    learning_rate=0.03,\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    verbose=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.eval_metrics(\n",
    "    data=pool1,\n",
    "    metrics=['Logloss','AUC'],\n",
    "    ntree_start=0,\n",
    "    ntree_end=0,\n",
    "    eval_period=1,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('AUC values:')\n",
    "print(np.array(metrics['AUC']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shap values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = model.get_feature_importance(pool1, fstr_type='ShapValues')\n",
    "print(shap_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(Pool(X, y, cat_features=cat_features))\n",
    "\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[3,:], X.iloc[3,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[91,:], X.iloc[91,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_small = X.iloc[0:200]\n",
    "shap_small = shap_values[:200]\n",
    "shap.force_plot(explainer.expected_value, shap_small, X_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from catboost.eval.catboost_evaluation import *\n",
    "learn_params = {'iterations': 20, # 2000\n",
    "                'learning_rate': 0.5, # we set big learning_rate,\n",
    "                                      # because we have small\n",
    "                                      # #iterations\n",
    "                'random_seed': 0,\n",
    "                'verbose': False,\n",
    "                'loss_function' : 'Logloss',\n",
    "                'boosting_type': 'Plain'}\n",
    "evaluator = CatboostEvaluation('amazon/train.tsv',\n",
    "                               fold_size=10000, # <= 50% of dataset\n",
    "                               fold_count=20,\n",
    "                               column_description='amazon/train.cd',\n",
    "                               partition_random_seed=0,\n",
    "                               #working_dir=... \n",
    ")\n",
    "result = evaluator.eval_features(learn_config=learn_params,\n",
    "                                 eval_metrics=['Logloss', 'Accuracy'],\n",
    "                                 features_to_eval=[6, 7, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost.eval.evaluation_result import *\n",
    "logloss_result = result.get_metric_results('Logloss')\n",
    "logloss_result.get_baseline_comparison(\n",
    "    ScoreConfig(ScoreType.Rel, overfit_iterations_info=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_best_model = CatBoostClassifier(iterations=10)\n",
    "my_best_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    cat_features=cat_features,\n",
    "    verbose=False\n",
    ")\n",
    "my_best_model.save_model('catboost_model.bin')\n",
    "my_best_model.save_model('catboost_model.json', format='json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_best_model.load_model('catboost_model.bin')\n",
    "print(my_best_model.get_params())\n",
    "print(my_best_model.random_seed_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoost\n",
    "fast_model = CatBoostClassifier(\n",
    "    random_seed=63,\n",
    "    iterations=150,\n",
    "    learning_rate=0.01,\n",
    "    boosting_type='Plain',\n",
    "    bootstrap_type='Bernoulli',\n",
    "    subsample=0.5,\n",
    "    one_hot_max_size=20,\n",
    "    rsm=0.5,\n",
    "    leaf_estimation_iterations=5,\n",
    "    max_ctr_complexity=1)\n",
    "\n",
    "fast_model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    verbose=False,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunned_model = CatBoostClassifier(\n",
    "    random_seed=63,\n",
    "    iterations=1000,\n",
    "    learning_rate=0.03,\n",
    "    l2_leaf_reg=3,\n",
    "    bagging_temperature=1,\n",
    "    random_strength=1,\n",
    "    one_hot_max_size=2,\n",
    "    leaf_estimation_method='Newton'\n",
    ")\n",
    "tunned_model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_features,\n",
    "    verbose=False,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model after parameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = CatBoostClassifier(\n",
    "    random_seed=63,\n",
    "    iterations=int(tunned_model.tree_count_ * 1.2),\n",
    ")\n",
    "best_model.fit(\n",
    "    X, y,\n",
    "    cat_features=cat_features,\n",
    "    verbose=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate predictions for the contest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop('id', axis=1)\n",
    "test_pool = Pool(data=X_test, cat_features=cat_features)\n",
    "contest_predictions = best_model.predict_proba(test_pool)\n",
    "print('Predictoins:')\n",
    "print(contest_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('submit.csv', 'w')\n",
    "f.write('Id,Action\\n')\n",
    "for idx in range(len(contest_predictions)):\n",
    "    line = str(test_df['id'][idx]) + ',' + str(contest_predictions[idx][1]) + '\\n'\n",
    "    f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit your solution [here](https://www.kaggle.com/c/amazon-employee-access-challenge/submit).\n",
    "Good luck!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "widgets": {
   "state": {
    "1057714ebc614324aa3ba2cf69408966": {
     "views": [
      {
       "cell_index": 17
      }
     ]
    },
    "8381e9eed05f4a03905ae8a56d7ab4ea": {
     "views": [
      {
       "cell_index": 48
      }
     ]
    },
    "f49684e8c5c44241bfe2c7f577f5cb41": {
     "views": [
      {
       "cell_index": 53
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
